{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini API: Function Calling"
      ],
      "metadata": {
        "id": "QVriLoUiRZmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "1PEbg4MtTTiG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wko9cvMiNwme"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "fvYqqsZnOILn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "ygVKV-nxOK60"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Function\n"
      ],
      "metadata": {
        "id": "wsMUFmUaTZzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini has the ability to call user-defined functions. Let's take a look at how exactly to do this. Firstly, let us define some functions relating to a hypothetical Italian restaurant located in Berkeley."
      ],
      "metadata": {
        "id": "cLIDhRAfTgfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_full_menu(service: str):\n",
        "    \"\"\"List all items on the menu of Gemini's Trattoria for the given service.\n",
        "\n",
        "    Args:\n",
        "        name: The type of service, lunch or dinner.\n",
        "    \"\"\"\n",
        "    return [\"Chicken Caesar Salad\", \"Margherita Pizza\", \"Spaghetti and Meatballs\", \"Eggplant Parmesan\"]\n",
        "\n",
        "\n",
        "def find_vegetarian_items(items: list[str]):\n",
        "    \"\"\"List all dishes in items that are vegetarian.\n",
        "\n",
        "    Args:\n",
        "        items: A list of dinner dishes.\n",
        "    \"\"\"\n",
        "    return [\"Margherita Pizza\", \"Eggplant Parmesan\"]\n",
        "\n",
        "def enter_restaurant():\n",
        "    \"\"\"You enter Gemini's Trattoria, moving the creaky door.\"\"\"\n",
        "    print(\"The door swings open, making a loud noise.\")\n",
        "    return True\n",
        "\n",
        "functions = {\"get_full_menu\": get_full_menu,\n",
        "             \"find_vegetarian_items\": find_vegetarian_items,\n",
        "             \"enter_restaurant\": enter_restaurant}"
      ],
      "metadata": {
        "id": "IIe-cXLHOWoo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we go ahead and define our Gemini model. Notice how we include the argument for tools, which tells the model which functions it has available to use. We create a chat and set automatic function calling to True, which we will touch on later."
      ],
      "metadata": {
        "id": "qQDJ_k4qfhb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.5-flash\", tools=functions.values()\n",
        ")\n",
        "\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)"
      ],
      "metadata": {
        "id": "V8stPgRtOaEN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we go ahead and send a prompt that requires the model to call our user-defined functions."
      ],
      "metadata": {
        "id": "hSR_d9Mofu_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"What items are on Gemini's Trattoria's dinner menu?\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "enDA7oh7OeGO",
        "outputId": "b532bd03-31e9-484c-921b-da99e94c6577"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dinner menu at Gemini's Trattoria features Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in the chat history, the model initially sends back a function call, to which we automatically respond, which then leads to the final model output."
      ],
      "metadata": {
        "id": "C7miJvuiCLJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mZCERSwOhuh",
        "outputId": "ac09d868-8bc1-4638-aaed-4a3137647f20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items are on Gemini's Trattoria's dinner menu?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'get_full_menu', 'response': {'result': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"The dinner menu at Gemini's Trattoria features Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Behind The Scenes"
      ],
      "metadata": {
        "id": "AiGwwQs6TkiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, the processes goes as follows:\n",
        "1. The user submits a query to the model.\n",
        "2. The model responds with a function call.\n",
        "3. The user runs the function and returns the result of the function.\n",
        "4. Now, the model will either go back to Step 2 or output a final response, as seen above.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://video.udacity-data.com/topher/2024/June/66749652_function_calling/function_calling.jpeg\" width=\"500\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "mQ1gZGNyTrPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see this step-by-step in action by running the previous example with manual function calling, by setting the automatic function calling argument to False."
      ],
      "metadata": {
        "id": "in9bG0g7kXn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(enable_automatic_function_calling=False)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items are on Gemini's Trattoria's dinner menu?\"\n",
        ")\n",
        "\n",
        "part = response.candidates[0].content.parts[0]\n",
        "part"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "yp-3ixnGkuHr",
        "outputId": "3c363e89-89c7-4dce-d37c-3ab6b1a6fca0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "function_call {\n",
              "  name: \"get_full_menu\"\n",
              "  args {\n",
              "    fields {\n",
              "      key: \"service\"\n",
              "      value {\n",
              "        string_value: \"dinner\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we can reply to the model as specified in Step 3, using the functions dictionary we made earlier."
      ],
      "metadata": {
        "id": "5kYKYoDElpzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.ai.generativelanguage as glm\n",
        "from google.protobuf.struct_pb2 import Struct\n",
        "\n",
        "# Put the result in a protobuf Struct\n",
        "s = Struct()\n",
        "result = functions[part.function_call.name](**part.function_call.args)\n",
        "s.update({\"result\": result})\n",
        "\n",
        "function_response = glm.Part(\n",
        "    function_response=glm.FunctionResponse(name=\"get_full_menu\", response=s)\n",
        ")\n",
        "\n",
        "# Generate the next response\n",
        "response = chat.send_message(function_response)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bCD47Ry7lpKx",
        "outputId": "c75c8f38-293f-41ba-ac68-a0adf18bcd40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dinner menu at Gemini's Trattoria includes Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Function Calls"
      ],
      "metadata": {
        "id": "S3q5nWqyoj6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model can also call multiple functions in a row, either at the same time or one after the other, as we see in both cases below."
      ],
      "metadata": {
        "id": "Iug5VBZ5kWw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items on Gemini's Trattoria's dinner menu are vegetarian?\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "S7_gRd2QQCId",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52763bde-fec6-47cb-d2c5-a3ebd1db19b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vegetarian options on Gemini's Trattoria's dinner menu are Margherita Pizza and Eggplant Parmesan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJNvCH77jaYf",
        "outputId": "30d0554d-742f-448f-cf38-9728765694b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items on Gemini's Trattoria's dinner menu are vegetarian?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'get_full_menu', 'response': {'result': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'find_vegetarian_items', 'args': {'items': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'find_vegetarian_items', 'response': {'result': ['Margherita Pizza', 'Eggplant Parmesan']}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"The vegetarian options on Gemini's Trattoria's dinner menu are Margherita Pizza and Eggplant Parmesan.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Your are standing outside of Gemini's Trattoria. Enter the restaurant and read out the items on the menu.\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9WqeUW_zoadm",
        "outputId": "a699c716-a0de-4590-9047-6cd57ad2e95f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The door swings open, making a loud noise.\n",
            "I have entered Gemini's Trattoria. The dinner menu features: Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaP34mbbpUyx",
        "outputId": "4174d62b-37ef-45a1-8750-b5bbc2874d36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"Your are standing outside of Gemini's Trattoria. Enter the restaurant and read out the items on the menu.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'enter_restaurant', 'args': {}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'enter_restaurant', 'response': {'result': True}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'get_full_menu', 'response': {'result': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"I have entered Gemini's Trattoria. The dinner menu features: Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling Config"
      ],
      "metadata": {
        "id": "5hAZc4iCp20w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a function calling config lets us control how the Gemini API acts when tools have been specified. Let us use the same previous example and see what happens in each of three cases."
      ],
      "metadata": {
        "id": "bXF1laiBqVkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ],
      "metadata": {
        "id": "MS_lpBLRpuli"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we use the NONE mode, which tells the model to not make any function calls. In this example, the model knows about the get_full_menu function but is unable to use it."
      ],
      "metadata": {
        "id": "2MkyISN3rCVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items on Gemini's Trattoria's dinner menu are vegetarian?\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "IOnPq6zVrMCq",
        "outputId": "e764ce57-03d8-4851-e097-508fd89a4cc0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items on Gemini's Trattoria's dinner menu are vegetarian?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"I can't access real-time, live restaurant menus, and menus can change frequently based on season, chef specials, or even daily availability.\\n\\nTo get the most accurate and up-to-date information, I strongly recommend one of the following:\\n\\n1.  **Check Gemini's Trattoria's Official Website:** Most restaurants post their current menus online.\\n2.  **Call the Restaurant Directly:** This is the best way to confirm vegetarian options and discuss any dietary needs you might have with their staff.\\n\\n**However, based on typical Italian trattoria offerings, here are common types of items that are usually vegetarian:**\\n\\n**Antipasti (Appetizers):**\\n*   **Bruschetta Pomodoro:** Toasted bread with fresh tomatoes, basil, garlic, and olive oil.\\n*   **Caprese Salad:** Sliced fresh mozzarella, tomatoes, basil, and olive oil.\\n*   **Focaccia with Olive Oil:** Italian flatbread.\\n*   **Olives or Marinated Artichokes**\\n*   **Arancini:** (Ask for cheese/rice filling, sometimes they have meat)\\n\\n**Insalate (Salads):**\\n*   **Mixed Green Salad:** With a vinaigrette dressing.\\n*   **Arugula Salad:** Often with Parmesan (ask about rennet if strict vegetarian), lemon, and olive oil.\\n*   **Caesar Salad:** (Ask for no anchovies in the dressing, and no chicken if usually served with protein).\\n\\n**Primi Piatti (Pastas & Grains):**\\n*   **Pasta al Pomodoro/Marinara:** Pasta with a simple tomato sauce.\\n*   **Pasta Aglio e Olio:** Pasta with garlic and olive oil.\\n*   **Penne Arrabiata:** Pasta with a spicy tomato sauce.\\n*   **Pesto Pasta:** (Confirm if their pesto contains any non-vegetarian ingredients, though it's usually pine nuts, basil, garlic, Parmesan, and olive oil).\\n*   **Ravioli/Gnocchi/Tortellini:** Often available with cheese (ricotta, spinach & ricotta) or vegetable fillings.\\n*   **Risotto Funghi:** Mushroom risotto (confirm vegetable broth).\\n*   **Melanzane alla Parmigiana:** Eggplant Parmesan (a classic baked dish).\\n\\n**Contorni (Sides):**\\n*   SautÃ©ed Spinach\\n*   Roasted Potatoes\\n*   Broccolini\\n*   Mixed Vegetables\\n\\n**Dolci (Desserts):**\\n*   Most desserts like **Tiramisu**, **Panna Cotta**, **Gelato**, and **Sorbetto** are vegetarian.\\n\\nWhen you contact the restaurant, it's always good to specifically ask about ingredients like chicken/beef broth in sauces, animal rennet in cheeses (especially Parmesan), or any hidden meat products like pancetta in dishes.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUTO mode lets the model decide whether to reply with text or to call specific functions. In this example, we see that the model calls a function to get all menu items but is able to reason on its own on which items are pasta dishes."
      ],
      "metadata": {
        "id": "QIDmVQUfrqh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items on Gemini's Trattoria's dinner menu are pasta dishes?\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "B3kOMeGirZAp",
        "outputId": "3113a9e2-f0bb-4e5f-d8eb-b1c4b7df1f75"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items on Gemini's Trattoria's dinner menu are pasta dishes?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': 'I can only list all the items on the dinner menu, not filter for pasta dishes. Would you like to see the full dinner menu?'}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, ANY mode forces the model to make function calls, as seen in the below example. We decide to switch over to the Gemini 1.5 Pro model to achieve the intended behavior."
      ],
      "metadata": {
        "id": "jMwHF05_sTW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.5-pro\", tools=functions.values()\n",
        ")\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\")\n",
        "chat = model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Enter Gemini's Trattoria.\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "5rn0Xoi6ryDv",
        "outputId": "2222c631-ed48-4560-c162-9e6ffabd2741"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"Enter Gemini's Trattoria.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'enter_restaurant', 'args': {}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting allowed_function_names, the model will only choose from those functions. If it is not set, all of the functions in tools are candidates for function calling. In the below example, since we are in ANY mode, the model is forced to use a function, even though it is not necessarily the best option."
      ],
      "metadata": {
        "id": "_ribpz_fszjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"any\", [\"get_full_menu\"])\n",
        "chat = model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Enter Gemini's Trattoria.\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Z_lU1Xntu9ps",
        "outputId": "a3943cd4-5b03-4790-b050-4b39cbd024d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"Enter Gemini's Trattoria.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}, 'id': ''}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vd2ALTSCxA47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}